{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TensorFlow\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# import other modules\n",
    "import beatmup\n",
    "import beatmup_keras\n",
    "import numpy\n",
    "import os\n",
    "import sys\n",
    "from model import make_model\n",
    "from imagenet_tools import ImageSet\n",
    "\n",
    "# Set global configuration\n",
    "\n",
    "# path to ImageNet 2012 dataset\n",
    "imagenet_path = '/imagenet'\n",
    "\n",
    "# folder to store checkpoints during training\n",
    "checkpoints_dir = 'checkpoints'\n",
    "\n",
    "# classes numbers: 119 dogs and tiger cat\n",
    "classes = list(range(151,269)) + [275, 282]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setting up the model\n",
    "model = make_model(input_size=385, activation=beatmup_keras.sigmoid_like, num_classes=120)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation set loading\n",
    "image_size = model.layers[0].input_shape[0][1]\n",
    "val_set = ImageSet(os.path.join(imagenet_path, 'Annotations', 'CLS-LOC', 'val'),\n",
    "                   os.path.join(imagenet_path, 'Data', 'CLS-LOC', 'val'),\n",
    "                   os.path.join(imagenet_path, 'val_cache.txt'),\n",
    "                   batch_size=1,\n",
    "                   image_size=image_size,\n",
    "                   use_annotations=False)\n",
    "val_set.supply_class_names('map_clsloc.txt')\n",
    "val_set.filter(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint loading\n",
    "from glob import glob\n",
    "checkpoint_files = sorted(glob(os.path.join(checkpoints_dir, '*.h5')))\n",
    "\n",
    "if not checkpoint_files:\n",
    "    raise Exception(\"No checkpoint found in '%s'\" % (checkpoints_dir))\n",
    "model.load_weights(checkpoint_files[-1])\n",
    "print('Loading %s' % (checkpoint_files[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run validation pass\n",
    "model.evaluate(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beatmup model export\n",
    "\n",
    "# Convert the model into Beatmup model\n",
    "ctx = beatmup.Context()\n",
    "beatmup_model, beatmup_model_data = beatmup_keras.export_model(model, ctx)\n",
    "\n",
    "# Add image sampler at the beginning\n",
    "image_size = model.layers[0].input_shape[0][1]\n",
    "tail = beatmup_model.get_first_operation()\n",
    "sampler = beatmup.nnets.ImageSampler(\"input\", (image_size, image_size))\n",
    "beatmup_model.add_operation(tail.name, sampler)\n",
    "beatmup_model.add_connection(sampler.name, tail.name)\n",
    "\n",
    "# Add softmax at the end\n",
    "beatmup_model.append(beatmup.nnets.Softmax(\"softmax\"), True)\n",
    "\n",
    "# Serialize the model, put the model into \"\" chunk (sort of convention)\n",
    "code = beatmup_model.serialize()\n",
    "beatmup_model_data[\"\"] = code.encode(\"ascii\")\n",
    "\n",
    "# Add class names\n",
    "beatmup_model_data[\"labels\"] = \"\".join(val_set.class_names).encode(\"ascii\")\n",
    "\n",
    "# Save to a chunkfile\n",
    "beatmup_model_data.save(\"dog_classifier.chunks\", False)\n",
    "\n",
    "print('All good.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation pass with Beatmup model\n",
    "inference = beatmup.nnets.InferenceTask(beatmup_model, beatmup_model_data)\n",
    "input_op = beatmup_model.get_first_operation()\n",
    "softmax_op = beatmup_model.get_last_operation()\n",
    "\n",
    "score = 0\n",
    "for i in range(len(val_set)):\n",
    "    # Get image from training set\n",
    "    image, labels = val_set[i]\n",
    "    image = beatmup.Bitmap(ctx, image)\n",
    "\n",
    "    # Connect image to the inference task\n",
    "    inference.connect(image, input_op)\n",
    "    \n",
    "    # Run inference\n",
    "    ctx.perform_task(inference)\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    probabilities = softmax_op.get_probabilities()\n",
    "    \n",
    "    # Get the class label\n",
    "    prediction = numpy.argmax(probabilities)\n",
    "    \n",
    "    # Compare with the ground truth\n",
    "    ground_truth = numpy.argmax(labels)\n",
    "    if prediction == ground_truth:\n",
    "        score += 1\n",
    "\n",
    "    # Print some info\n",
    "    num_images = i + 1\n",
    "    acc  = 100 * score / num_images\n",
    "    print('\\r %d / %d images, accuracy: %0.2f%%' % (num_images, len(val_set), acc), end='')\n",
    "    \n",
    "    # Collect garbage\n",
    "    ctx.empty_gpu_recycle_bin()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
