{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# append PYTHONPATH to load extensions\n",
    "sys.path.append('fastaugment')\n",
    "sys.path.append('sigmoid_like_tf_op')\n",
    "\n",
    "# load TensorFlow\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# import other modules\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.data.experimental import AUTOTUNE\n",
    "from model import make_model\n",
    "from imagenet_tools import ImageSet\n",
    "from fast_augment import augment\n",
    "from sigmoid_like import sigmoid_like\n",
    "from glob import glob\n",
    "\n",
    "# Set global configuration\n",
    "\n",
    "# path to ImageNet 2012 dataset\n",
    "imagenet_path = '/imagenet'\n",
    "\n",
    "# filename pattern on where to store the training set TF record cache\n",
    "tfrecord_pattern = os.path.join(imagenet_path, 'dogs_subset', \"train-*.tfrecord\")\n",
    "\n",
    "# folder to store checkpoints during training\n",
    "checkpoints_dir = 'checkpoints'\n",
    "\n",
    "# classes numbers: 119 dogs and tiger cat\n",
    "classes = list(range(151,269)) + [275, 282]\n",
    "\n",
    "# training and validation batch sizes\n",
    "train_batch_size = 64\n",
    "valid_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the model\n",
    "model = make_model(input_size=385, activation=sigmoid_like, num_classes=120)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "\n",
    "# Get image size in pixels from the model\n",
    "image_size = model.layers[0].input_shape[0][1]\n",
    "\n",
    "# Load training set as an ImageSet.\n",
    "# This takes some time the very first time to write relevant information into a cache file (train_cache.txt)\n",
    "train_set = ImageSet(os.path.join(imagenet_path, 'Annotations', 'CLS-LOC', 'train'),\n",
    "                     os.path.join(imagenet_path, 'Data', 'CLS-LOC', 'train'),\n",
    "                     os.path.join(imagenet_path, 'train_cache.txt'),\n",
    "                     batch_size=train_batch_size,\n",
    "                     image_size=image_size)\n",
    "\n",
    "# Supply class names to the training set\n",
    "train_set.supply_class_names('map_clsloc.txt')\n",
    "\n",
    "# Filter the training set to keep only the selected classes\n",
    "train_set.filter(classes)\n",
    "\n",
    "# Shuffle the training set\n",
    "train_set.shuffle()\n",
    "\n",
    "# Make TFRecord for the training set for better speed in training.\n",
    "# Takes additional ~25 GB and some time when run the first time.\n",
    "train_set.make_tfrecord(tfrecord_pattern, 16)\n",
    "\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    \"\"\" TF Record file reading function\n",
    "    \"\"\"\n",
    "    tfrecord_format = ({\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    })\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = tf.io.decode_jpeg(example[\"image\"], channels=3)\n",
    "    label = tf.cast(example[\"label\"], tf.int32)\n",
    "    return image, tf.one_hot(label, len(classes))\n",
    "\n",
    "\n",
    "def dataset_from_tfrecord(pattern, batch_size):\n",
    "    \"\"\" Constructs a TFRecordDataset\n",
    "    \"\"\"\n",
    "    ignore_order = tf.data.Options()\n",
    "    ignore_order.experimental_deterministic = False      # disable order, increase speed\n",
    "    dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(pattern))\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.shuffle(batch_size, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(lambda x, y: augment(x, y,\n",
    "                                               mixup=0.5,\n",
    "                                               perspective=20))    # enable augmentation\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Turn training set from ImageSet to an augmented TFRecordDataset\n",
    "train_set = dataset_from_tfrecord(tfrecord_pattern, train_set.batch_size)\n",
    "\n",
    "\n",
    "# Proceed similarly with the validation set.\n",
    "# No TF record here, but could be.\n",
    "val_set = ImageSet(os.path.join(imagenet_path, 'Annotations', 'CLS-LOC', 'val'),\n",
    "                   os.path.join(imagenet_path, 'Data', 'CLS-LOC', 'val'),\n",
    "                   os.path.join(imagenet_path, 'val_cache.txt'),\n",
    "                   batch_size=valid_batch_size,\n",
    "                   image_size=image_size,\n",
    "                   use_annotations=False)\n",
    "val_set.supply_class_names('map_clsloc.txt')\n",
    "val_set.filter(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample augmented images from the training set\n",
    "it = train_set.take(1).unbatch().as_numpy_iterator()\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    image, _ = next(it)\n",
    "    plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images of a specific class from the validation set\n",
    "class_idx = 119\n",
    "imgs = val_set.samples(class_idx)\n",
    "\n",
    "# Plot the images\n",
    "plt.figure(figsize=(12,12))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    image, class_name = next(imgs)\n",
    "    plt.imshow(image, cmap=plt.cm.binary)\n",
    "plt.suptitle(class_name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load last checkpoint if available\n",
    "\n",
    "checkpoint_files = sorted(glob(os.path.join(checkpoints_dir, '*.h5')))\n",
    "initial_epoch = len(checkpoint_files)\n",
    "\n",
    "if checkpoint_files:\n",
    "    model.load_weights(checkpoint_files[initial_epoch - 1])\n",
    "    print('Loading %s (epoch %d)' % (checkpoint_files[initial_epoch - 1], initial_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FFEEEEAAAAATTTTTT\n",
    "\n",
    "if initial_epoch == 0:\n",
    "    !rm -rf logs\n",
    "    !rm checkpoints/*.h5\n",
    "\n",
    "# set up saving callback\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(checkpoints_dir, 'weights{epoch:04d}-{loss:.2f}.h5'),\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=False,\n",
    "    save_weights_only=True,\n",
    "    mode='min')\n",
    "\n",
    "# define LR schedule\n",
    "def lr_scheduler(epoch, _, initial_lr=0.01, cliff=400, step=50):\n",
    "    step = max(0, (epoch - cliff) // step + 1)\n",
    "    factor = 0.5\n",
    "    lr = initial_lr * (factor ** step)\n",
    "    return lr\n",
    "\n",
    "# fit\n",
    "model.fit(train_set,\n",
    "          initial_epoch=initial_epoch, epochs=600,\n",
    "          validation_data=val_set,\n",
    "          callbacks=[save_callback,\n",
    "                     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "                     tf.keras.callbacks.LearningRateScheduler(lr_scheduler)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Run validation pass\n",
    "model.evaluate(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average of selected checkpoints\n",
    "\n",
    "# Get checkpoint files\n",
    "checkpoint_files = glob(os.path.join('ensembling','*.h5'))\n",
    "print('Averaging', len(checkpoint_files), 'models')\n",
    "\n",
    "# Load and grab weights in an array\n",
    "weights = []\n",
    "for entry in checkpoint_files:\n",
    "    model.load_weights(entry)\n",
    "    weights.append(model.get_weights())\n",
    "\n",
    "# Compute the average\n",
    "avg_weights = []\n",
    "for i in range(len(weights[0])):\n",
    "    avg_weights.append(numpy.array([w[i] for w in weights]).mean(axis=0))\n",
    "\n",
    "# Assign the averaged weights to the model\n",
    "model.set_weights(avg_weights)\n",
    "model.evaluate(val_set)\n",
    "\n",
    "# Save the model\n",
    "model.save_weights('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
